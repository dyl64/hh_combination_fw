{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe7f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n",
      "\n",
      "\u001b[1mRooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby\u001b[0m \n",
      "                Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University\n",
      "                All rights reserved, please read http://roofit.sourceforge.net/license.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import quickstats\n",
    "import sys, numpy as np\n",
    "from quickstats.components import AnalysisBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab599ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure hh combination fw path is defined\n",
    "hh_comb_fw_path = os.environ.get('hh_combination_fw_path', None)\n",
    "\n",
    "assert hh_comb_fw_path\n",
    "\n",
    "gen_command = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc5f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quickstats.maths.numerics import is_integer, pretty_value\n",
    "from pprint import pprint\n",
    "def create_job(string, key):\n",
    "    tmp = string.split(',')\n",
    "    poi1 = tmp[0].split('=')[0]\n",
    "    poi2 = tmp[1].split('=')[0]\n",
    "    poi1_tmp = tmp[0].split('=')[1].split('_')\n",
    "    poi2_tmp = tmp[1].split('=')[1].split('_')\n",
    "    poi1_range = [float(p) for p in poi1_tmp[0:2]]\n",
    "    poi1_step = float(poi1_tmp[2])\n",
    "    poi2_range = [float(p) for p in poi2_tmp[0:2]]\n",
    "    poi2_step = float(poi2_tmp[2])\n",
    "\n",
    "    poi1_nsteps = int((poi1_range[1] - poi1_range[0]) / poi1_step)\n",
    "    poi2_nsteps = int((poi2_range[1] - poi2_range[0]) / poi2_step)\n",
    "\n",
    "    # slice poi1 with full poi2 range\n",
    "    if poi1_nsteps < poi2_nsteps and poi2_nsteps > 12:\n",
    "        poi1, poi1_range, poi1_step, poi1_nsteps, poi2, poi2_range, poi2_step, poi2_nsteps = poi2, poi2_range, poi2_step, poi2_nsteps, poi1, poi1_range, poi1_step, poi1_nsteps\n",
    "        \n",
    "    poi_slice_up = np.arange(poi1_range[0], poi1_range[1], poi1_step).round(decimals=2)\n",
    "    new_dict = {}\n",
    "    for i in range(poi1_nsteps):\n",
    "        key_name = key+f'_job{i+1}'\n",
    "        value = f\"^{poi1}={poi_slice_up[i]}_{pretty_value(poi_slice_up[i]+poi1_step)}_{poi1_step},{poi2}={pretty_value(poi2_range[0])}_{pretty_value(poi2_range[1])}_{poi2_step}^\"\n",
    "        new_dict[key_name] = value\n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f661e6",
   "metadata": {},
   "source": [
    "## Step 1: Configure task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a485add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the input timestamp to use\n",
    "timestamp = \"20220520\"\n",
    "withbr = 'with' # 'without'\n",
    "\n",
    "paths = {\n",
    "    'input'              : os.path.join(hh_comb_fw_path, \"FullRun2Workspaces\", \"original\", \"HHH2022\", timestamp),\n",
    "    'task_options'       : os.path.join(hh_comb_fw_path, \"configs\", \"task_options\"       , \"HHH2022\",\n",
    "                                        f\"nonres_kl_kt_likelihood_{withbr}_BR_decorrelation.yaml\"),\n",
    "    'correlation_schemes': os.path.join(hh_comb_fw_path, \"configs\", \"correlation_schemes\", \"HHH2022\", \n",
    "                                        \"nonres_kl_v12.json\"),\n",
    "    #'output'             : os.path.join(os.getcwd(), f\"outputs_HHH2022_{timestamp}\")\n",
    "    'output'             : os.path.join(os.getcwd(), f\"outputs_HHH2022_{timestamp}_{withbr}_BR_decorrelation\")\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'resonant_type': 'nonres',\n",
    "    'channels'     : ['bbbb', 'bbtautau', 'bbyy'],\n",
    "    'file_expr'    : '<mass[F]>_kl',\n",
    "    'blind'        : False,\n",
    "    'cache'        : True,\n",
    "    'experimental' : True,\n",
    "    'parallel'     : -1\n",
    "}\n",
    "\n",
    "options = {\n",
    "    \"input_dir\"    : paths['input'],\n",
    "    \"resonant_type\": config['resonant_type'],\n",
    "    \"channels\"     : \",\".join(config['channels']),\n",
    "    \"outdir\"       : paths['output'],\n",
    "    \"file_expr\"    : f\"\\\"{config['file_expr']}\\\"\",\n",
    "    \"config\"       : paths['task_options'],\n",
    "    \"parallel\"     : config['parallel'],\n",
    "    \"skip-limit\"   : \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd2c1d",
   "metadata": {},
   "source": [
    "## Step 2: Prepare modified channel workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e938d278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HHComb process_channels --input_dir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/FullRun2Workspaces/original/HHH2022/20220520 --resonant_type nonres --channels bbbb,bbtautau,bbyy --outdir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation --file_expr \"<mass[F]>_kl\" --config /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/configs/task_options/HHH2022/nonres_kl_kt_likelihood_with_BR_decorrelation.yaml --parallel -1 --skip-limit  --experimental  --cache \n"
     ]
    }
   ],
   "source": [
    "if config[\"blind\"]:\n",
    "    options[\"blind\"] = \"\"\n",
    "else:\n",
    "    options[\"unblind\"] : \"\"\n",
    "if config[\"experimental\"]:\n",
    "    options[\"experimental\"] = \"\"\n",
    "else:\n",
    "    options[\"official\"] : \"\"\n",
    "if config['cache']:\n",
    "    options['cache'] = \"\"\n",
    "else:\n",
    "    options['no-cache'] = \"\"\n",
    "command_str = \"HHComb process_channels \" + \" \".join([f\"--{key} {value}\" for key, value in options.items()])\n",
    "print(command_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba857a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not gen_command:\n",
    "    os.system(command_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89915d5",
   "metadata": {},
   "source": [
    "## Step 3: Prepare combined workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dd32434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HHComb combine_ws --input_dir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation --resonant_type nonres --channels bbbb,bbtautau,bbyy --file_expr \"<mass[F]>_kl\" --config /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/configs/task_options/HHH2022/nonres_kl_kt_likelihood_with_BR_decorrelation.yaml --scheme /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/configs/correlation_schemes/HHH2022/nonres_kl_v12.json --parallel -1 --skip-limit  --experimental  --cache \n"
     ]
    }
   ],
   "source": [
    "def return_combine_command(paths, config):\n",
    "    options = {\n",
    "        \"input_dir\"    : paths['output'],\n",
    "        \"resonant_type\": config['resonant_type'],\n",
    "        \"channels\"     : \",\".join(config['channels']),\n",
    "        \"file_expr\"    : f\"\\\"{config['file_expr']}\\\"\",\n",
    "        \"config\"       : paths['task_options'],\n",
    "        \"scheme\"       : paths['correlation_schemes'],\n",
    "        \"parallel\"     : config['parallel'],\n",
    "        \"skip-limit\"   : \"\"\n",
    "    }\n",
    "    if config[\"blind\"]:\n",
    "        options[\"blind\"] = \"\"\n",
    "    else:\n",
    "        options[\"unblind\"] : \"\"\n",
    "    if config[\"experimental\"]:\n",
    "        options[\"experimental\"] = \"\"\n",
    "    else:\n",
    "        options[\"official\"] : \"\"\n",
    "    if config['cache']:\n",
    "        options['cache'] = \"\"\n",
    "    else:\n",
    "        options['no-cache'] = \"\"\n",
    "    command_str = \"HHComb combine_ws \" + \" \".join([f\"--{key} {value}\" for key, value in options.items()])\n",
    "    print(command_str)\n",
    "    return command_str\n",
    "\n",
    "command_str = return_combine_command(paths, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "984c94e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not gen_command:\n",
    "    os.system(command_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf365de6",
   "metadata": {},
   "source": [
    "**Checkout the rescaled workspace paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b31d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbbb': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbbb/0_kl.root',\n",
       " 'bbtautau': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbtautau/0_kl.root',\n",
       " 'bbyy': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbyy/0_kl.root',\n",
       " 'combined': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/combined/nonres/A-bbbb_bbtautau_bbyy-fullcorr/0_kl.root'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_ws_paths = {}\n",
    "for channel in config['channels']:\n",
    "    ws_path = os.path.join(paths['output'], 'rescaled', config['resonant_type'], channel, \"0_kl.root\")\n",
    "    rescaled_ws_paths[channel]  = ws_path\n",
    "# rescaled workspace path for combined workspacee\n",
    "ws_path = glob.glob(os.path.join(paths['output'], 'combined', config['resonant_type'], \"*\", \"0_kl.root\"))[0]\n",
    "rescaled_ws_paths[\"combined\"] = ws_path\n",
    "rescaled_ws_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937bb2f",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Asimov workspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b83b571",
   "metadata": {},
   "source": [
    "**Set up the asimov workspace paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e328a0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbbb': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbbb/0_asimov.root',\n",
       " 'bbtautau': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbtautau/0_asimov.root',\n",
       " 'bbyy': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbyy/0_asimov.root',\n",
       " 'combined': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/combined/nonres/A-bbbb_bbtautau_bbyy-fullcorr/0_asimov.root'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asimov_ws_paths = {}\n",
    "for channel in rescaled_ws_paths:\n",
    "    rescaled_ws_path = rescaled_ws_paths[channel]\n",
    "    asimov_ws_path   = os.path.join(os.path.dirname(rescaled_ws_path), \"0_asimov.root\")\n",
    "    asimov_ws_paths[channel] = asimov_ws_path\n",
    "asimov_ws_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee361c52",
   "metadata": {},
   "source": [
    "**Generate CLI commands**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96896c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quickstats generate_standard_asimov --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbbb/0_kl.root --output_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbbb/0_asimov.root --poi xsec_br --data combData --asimov_types 2 &\n",
      "\n",
      "quickstats generate_standard_asimov --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbtautau/0_kl.root --output_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbtautau/0_asimov.root --poi xsec_br --data combData --asimov_types 2 &\n",
      "\n",
      "quickstats generate_standard_asimov --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbyy/0_kl.root --output_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbyy/0_asimov.root --poi xsec_br --data combData --asimov_types 2 &\n",
      "\n",
      "quickstats generate_standard_asimov --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/combined/nonres/A-bbbb_bbtautau_bbyy-fullcorr/0_kl.root --output_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/combined/nonres/A-bbbb_bbtautau_bbyy-fullcorr/0_asimov.root --poi xsec_br --data combData --asimov_types 2 &\n",
      "\n"
     ]
    }
   ],
   "source": [
    "options = {\n",
    "    'poi'         : 'xsec_br',\n",
    "    'data'        : 'combData',\n",
    "    'asimov_types': '2'\n",
    "}\n",
    "command_str_map = {}\n",
    "for channel in rescaled_ws_paths:\n",
    "    input_file  = rescaled_ws_paths[channel]\n",
    "    output_file = asimov_ws_paths[channel]\n",
    "    channel_options = {\"input_file\": input_file, \"output_file\": output_file, **options}\n",
    "    channel_command_str = \"quickstats generate_standard_asimov \" + \\\n",
    "                          \" \".join([f\"--{key} {value}\" for key, value in channel_options.items()])\n",
    "    command_str_map[channel] = channel_command_str\n",
    "    print(channel_command_str, '&')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43435905",
   "metadata": {},
   "source": [
    "**Generate asimov data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a25e4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not gen_command:\n",
    "    for channel, command_str in command_str_map.items():\n",
    "        print(f\"INFO: Generating asimov data for the channel \\\"{channel}\\\"\")\n",
    "        os.system(command_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab98f89",
   "metadata": {},
   "source": [
    "## Step 5: Prepare post-fit snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42898d19",
   "metadata": {},
   "source": [
    "**Set up the fitted workspace paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca7333e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbbb': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbbb/0_fitted.root',\n",
       " 'bbtautau': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbtautau/0_fitted.root',\n",
       " 'bbyy': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbyy/0_fitted.root',\n",
       " 'combined': '/afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/combined/nonres/A-bbbb_bbtautau_bbyy-fullcorr/0_fitted.root'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_ws_paths = {}\n",
    "for channel in asimov_ws_paths:\n",
    "    asimov_ws_path = asimov_ws_paths[channel]\n",
    "    fitted_ws_path = os.path.join(os.path.dirname(asimov_ws_path), \"0_fitted.root\")\n",
    "    fitted_ws_paths[channel] = fitted_ws_path\n",
    "fitted_ws_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65344ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_to_scan = [\"klambda\", \"kt\", \"kV\", \"k2V\", \"kF\", \"kH\", \"ktau\", \"klambda,kt\", \"kV,k2V\"]\n",
    "minimizer_options = {\n",
    "    \"retry\": 2,\n",
    "    \"eps\": 1\n",
    "}\n",
    "# observed and expected datasets\n",
    "datasets = {\n",
    "    \"observed\": \"combData\",\n",
    "    \"expected\": \"asimovData_muhat_NP_Profile\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34cce9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parallel channels\n",
    "import multiprocessing\n",
    "\n",
    "def run_best_fit(channel):\n",
    "    print(f\"==> Channel: {channel}\")\n",
    "    asimov_ws_path = asimov_ws_paths[channel]\n",
    "    fitted_ws_path = fitted_ws_paths[channel]\n",
    "    kwargs = {\n",
    "        \"filename\" : asimov_ws_path,\n",
    "        # only need to generate snapshot for observed data\n",
    "        \"data_name\": datasets[\"observed\"],\n",
    "        \"poi_name\": [],\n",
    "        \"config\": {**minimizer_options}\n",
    "    }\n",
    "    analysis = AnalysisBase(**kwargs)\n",
    "    # fix all pois at the beginning\n",
    "    analysis.setup_parameters(fix_param=\"<pois>\")\n",
    "    analysis.save_snapshot(analysis.kTempSnapshotName)\n",
    "    for poi_expr in pois_to_scan:\n",
    "        print(f\"==> POIs: {poi_expr}\")\n",
    "        analysis.setup_parameters(profile_param=poi_expr)\n",
    "        analysis.nll_fit(mode=3)\n",
    "        pois = poi_expr.split(\",\")\n",
    "        snapshot_name = f\"obs_bestfit_{'_'.join(pois)}\"\n",
    "        # save best-fit snapshot\n",
    "        analysis.save_snapshot(snapshot_name)\n",
    "        analysis.load_snapshot(analysis.kTempSnapshotName)\n",
    "    # restore initial snapshot\n",
    "    analysis.load_snapshot(analysis.kInitialSnapshotName)\n",
    "    analysis.save(fitted_ws_path)\n",
    "\n",
    "def driver_func():\n",
    "    PROCESSES = len(fitted_ws_paths)\n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        channels = list(fitted_ws_paths.keys())\n",
    "        results = [pool.apply_async(run_best_fit, (c, )) for c in channels]\n",
    "\n",
    "        for r in results:\n",
    "            print('\\t', r.get())\n",
    "\n",
    "if not gen_command:\n",
    "    driver_func()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a09ca",
   "metadata": {},
   "source": [
    "- By now, you should have the workspace `0_fitted.root` for each channel\n",
    "- Inside `0_fitted.root`, you have the observed dataset `combData` and the asimov dataset `asimovData_muhat_NP_Profile`\n",
    "- For each dataset, there are the corresponding muhat snapshots designed for each likelihood scan, e.g.\n",
    "  - obs_bestfit_klambda, obs_bestfit_kt, obs_bestfit_kV, obs_bestfit_k2V, obs_bestfit_klambda_kt, obs_bestfit_kV_k2V\n",
    "  - exp_bestfit_klambda, exp_bestfit_kt, exp_bestfit_kV, exp_bestfit_k2V, exp_bestfit_klambda_kt, exp_bestfit_kV_k2V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffe5fa1",
   "metadata": {},
   "source": [
    "## Step 6: Run likelihood scans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e52873",
   "metadata": {},
   "source": [
    "**Only commands are shown here since the jobs are computationally intensive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1746f452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'klambda': '^klambda=-6_12_0.2^'}\n"
     ]
    }
   ],
   "source": [
    "from quickstats.parsers import ParamParser\n",
    "\n",
    "# use '_job' + suffix to split scan range\n",
    "param_expr_maps = {\n",
    "    'klambda': \"^klambda=-6_12_0.2^\",\n",
    "#     \"klambda_kt_profile\": \"^klambda=-16_20_0.4,kt^\",\n",
    "#     \"klambda_kt_2D_final\": \"^klambda=-15_20_0.2,kt=-2_3_0.2^\",\n",
    "# #     \"kt\": \"^kt=-2_6_0.1^\",\n",
    "# #     \"kF\": \"^kF=-8_15_0.1^\",\n",
    "# #     \"kV\": \"^kV=-2.5_2.5_0.1^\",\n",
    "#     \"k2V\": \"^k2V=-3_5_0.1^\",\n",
    "#     \"kV_k2V_2D_final\": \"^kV=-3_3_0.2,k2V=-4_10_0.2^\",\n",
    "}\n",
    "\n",
    "# param_expr_maps.update(create_job('klambda=-15_20_0.2,kt=-2_3_0.2', 'klambda_kt_2D'))\n",
    "# param_expr_maps.update(create_job('kV=-3_3_0.2,k2V=-4_10_0.2', 'kV_k2V_2D'))\n",
    "pprint(param_expr_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0323cb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################################################################################\n",
      "# Channel: bbbb\n",
      "# Dataset: observed\n",
      "# Scan parameters: klambda\n",
      "quickstats likelihood_scan --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbbb/0_fitted.root --data combData --param_expr \"klambda=-6_12_0.2\" --outdir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/likelihood/observed/bbbb/klambda --snapshot obs_bestfit_klambda --retry 2 --eps 1\n",
      "\n",
      "# Dataset: expected\n",
      "# Scan parameters: klambda\n",
      "quickstats likelihood_scan --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbbb/0_fitted.root --data asimovData_muhat_NP_Profile --param_expr \"klambda=-6_12_0.2\" --outdir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/likelihood/expected/bbbb/klambda --snapshot asimovData_muhat_NP_Profile --retry 2 --eps 1\n",
      "\n",
      "#########################################################################################\n",
      "#########################################################################################\n",
      "# Channel: bbtautau\n",
      "# Dataset: observed\n",
      "# Scan parameters: klambda\n",
      "quickstats likelihood_scan --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbtautau/0_fitted.root --data combData --param_expr \"klambda=-6_12_0.2\" --outdir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/likelihood/observed/bbtautau/klambda --snapshot obs_bestfit_klambda --retry 2 --eps 1\n",
      "\n",
      "# Dataset: expected\n",
      "# Scan parameters: klambda\n",
      "quickstats likelihood_scan --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbtautau/0_fitted.root --data asimovData_muhat_NP_Profile --param_expr \"klambda=-6_12_0.2\" --outdir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/likelihood/expected/bbtautau/klambda --snapshot asimovData_muhat_NP_Profile --retry 2 --eps 1\n",
      "\n",
      "#########################################################################################\n",
      "#########################################################################################\n",
      "# Channel: bbyy\n",
      "# Dataset: observed\n",
      "# Scan parameters: klambda\n",
      "quickstats likelihood_scan --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbyy/0_fitted.root --data combData --param_expr \"klambda=-6_12_0.2\" --outdir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/likelihood/observed/bbyy/klambda --snapshot obs_bestfit_klambda --retry 2 --eps 1\n",
      "\n",
      "# Dataset: expected\n",
      "# Scan parameters: klambda\n",
      "quickstats likelihood_scan --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/rescaled/nonres/bbyy/0_fitted.root --data asimovData_muhat_NP_Profile --param_expr \"klambda=-6_12_0.2\" --outdir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/likelihood/expected/bbyy/klambda --snapshot asimovData_muhat_NP_Profile --retry 2 --eps 1\n",
      "\n",
      "#########################################################################################\n",
      "#########################################################################################\n",
      "# Channel: combined\n",
      "# Dataset: observed\n",
      "# Scan parameters: klambda\n",
      "quickstats likelihood_scan --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/combined/nonres/A-bbbb_bbtautau_bbyy-fullcorr/0_fitted.root --data combData --param_expr \"klambda=-6_12_0.2\" --outdir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/likelihood/observed/combined/klambda --snapshot obs_bestfit_klambda --retry 2 --eps 1\n",
      "\n",
      "# Dataset: expected\n",
      "# Scan parameters: klambda\n",
      "quickstats likelihood_scan --input_file /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/combined/nonres/A-bbbb_bbtautau_bbyy-fullcorr/0_fitted.root --data asimovData_muhat_NP_Profile --param_expr \"klambda=-6_12_0.2\" --outdir /afs/cern.ch/work/z/zhangr/HHcomb/hh_combination_fw/hh_combination_fw/tutorials/HHH2022/outputs_HHH2022_20220520_with_BR_decorrelation/likelihood/expected/combined/klambda --snapshot asimovData_muhat_NP_Profile --retry 2 --eps 1\n",
      "\n",
      "#########################################################################################\n"
     ]
    }
   ],
   "source": [
    "condor = False\n",
    "\n",
    "likelihood_scan_cmds = {}\n",
    "for channel in fitted_ws_paths:\n",
    "    likelihood_scan_cmds[channel] = {}\n",
    "    fitted_ws_path = fitted_ws_paths[channel]\n",
    "    for dataset_type, dataset_name in datasets.items():\n",
    "        likelihood_scan_cmds[channel][dataset_type] = {}\n",
    "        for key, expr in param_expr_maps.items():\n",
    "            if condor and 'final' in key:\n",
    "                continue\n",
    "            if not condor and 'job' in key:\n",
    "                continue\n",
    "            if 'final' in key:\n",
    "                outdir = os.path.join(paths['output'], 'likelihood', dataset_type, channel, key.replace('_final', ''))\n",
    "            else:\n",
    "                outdir = os.path.join(paths['output'], 'likelihood', dataset_type, channel, (key+'1')[:key.find('_job')])\n",
    "            pois = ParamParser._get_param_str_attributes(expr)\n",
    "            pois = [p.replace('^', '') for p in pois]\n",
    "            if dataset_type == \"observed\":\n",
    "                snapshot_name = f\"obs_bestfit_{'_'.join(pois)}\"\n",
    "            else:\n",
    "                snapshot_name = dataset_name\n",
    "            options = {\n",
    "                \"input_file\" : fitted_ws_path,\n",
    "                \"data\": dataset_name,\n",
    "                \"param_expr\": expr,\n",
    "                'outdir': outdir,\n",
    "                'snapshot': snapshot_name,\n",
    "                **minimizer_options\n",
    "            }\n",
    "            cmd_str = \"quickstats likelihood_scan \" + \\\n",
    "                      \" \".join([f\"--{key} {value}\" for key, value in options.items()])\n",
    "            likelihood_scan_cmds[channel][dataset_type][key] = cmd_str\n",
    "            \n",
    "            \n",
    "if condor:\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open(f'job{withbr}.txt', 'w')\n",
    "    print('save to', f'job{withbr}.txt')\n",
    "for channel in likelihood_scan_cmds:\n",
    "    if not condor:\n",
    "        print(\"#########################################################################################\")\n",
    "    print(f\"# Channel: {channel}\")\n",
    "    for dataset_type in likelihood_scan_cmds[channel]:\n",
    "        print(f\"# Dataset: {dataset_type}\")\n",
    "        for key in likelihood_scan_cmds[channel][dataset_type]:\n",
    "            if not condor:\n",
    "                print(f\"# Scan parameters: {key}\")\n",
    "            cmd_str = likelihood_scan_cmds[channel][dataset_type][key]\n",
    "            if not condor:\n",
    "                print(cmd_str.replace('^', '\"'))\n",
    "            else:\n",
    "                print(\"Arguments =\", cmd_str.replace(' ', '____'))\n",
    "                print(\"Queue 1\")\n",
    "        print()\n",
    "    if not condor:\n",
    "        print(\"#########################################################################################\")\n",
    "\n",
    "if condor: \n",
    "    sys.stdout = original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dbb59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c18768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
